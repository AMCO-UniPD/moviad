{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-04T16:00:35.164467Z",
     "start_time": "2024-12-04T16:00:09.758683Z"
    }
   },
   "source": [
    "from moviad.entrypoints.cfa import train_cfa\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T16:00:36.050019Z",
     "start_time": "2024-12-04T16:00:35.172526Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torchvision.models import MobileNet_V2_Weights\n",
    "from torchvision.transforms import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from main_scripts.main_cfa import main_train_cfa, main_test_cfa\n",
    "from moviad.datasets.mvtec.mvtec_dataset import MVTecDataset\n",
    "from moviad.datasets.realiad.realiad_dataset import RealIadDataset\n",
    "from moviad.datasets.realiad.realiad_dataset_configurations import RealIadClassEnum\n",
    "from moviad.datasets.visa.visa_dataset import VisaDataset\n",
    "from moviad.datasets.visa.visa_dataset_configurations import VisaDatasetCategory\n",
    "from moviad.utilities.configurations import TaskType, Split\n",
    "from tests.datasets.realiaddataset_tests import IMAGE_SIZE, REAL_IAD_DATASET_PATH, AUDIO_JACK_DATASET_JSON\n",
    "from tests.datasets.visadataset_tests import VISA_DATASET_PATH, VISA_DATASET_CSV_PATH\n",
    "from tests.main.common import get_training_args, MVTECH_DATASET_PATH, REALIAD_DATASET_PATH"
   ],
   "id": "c9e8de5f510c5c4",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T16:00:36.608900Z",
     "start_time": "2024-12-04T16:00:36.293513Z"
    }
   },
   "cell_type": "code",
   "source": [
    "MVTECH_DATASET_PATH = 'E:\\\\VisualAnomalyDetection\\\\datasets\\\\mvtec'\n",
    "REALIAD_DATASET_PATH = 'E:\\\\VisualAnomalyDetection\\\\datasets\\\\Real-IAD\\\\realiad_256'"
   ],
   "id": "70eee0ba9869730f",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## CFA Method",
   "id": "cc21e8387420d305"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Train CFA with MVTEC Dataset",
   "id": "7d3a8c9bda2a8349"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T16:00:36.783646Z",
     "start_time": "2024-12-04T16:00:36.613061Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torchvision.transforms import InterpolationMode\n",
    "# Seed: 3, 1024, 2048\n",
    "torch.manual_seed(3)\n",
    "args = get_training_args()\n",
    "args.dataset_path = MVTECH_DATASET_PATH\n",
    "args.category = 'pill'\n",
    "args.backbone = 'wide_resnet50_2'\n",
    "args.ad_layers = [\"layer1\", \"layer2\", \"layer3\"]\n",
    "args.save_path = \"./patch.pt\"\n",
    "args.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "args.epochs = 30\n",
    "args.model_checkpoint_path = \"./patch.pt\"\n",
    "args.visual_test_path = \"./visual_test\"\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(IMAGE_SIZE),\n",
    "    transforms.PILToTensor(),\n",
    "    transforms.Resize(\n",
    "        IMAGE_SIZE,\n",
    "        antialias=True,\n",
    "        interpolation=InterpolationMode.NEAREST,\n",
    "    ),\n",
    "    transforms.ConvertImageDtype(torch.float32)\n",
    "])"
   ],
   "id": "c47d7aae39394ac1",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T16:00:45.740045Z",
     "start_time": "2024-12-04T16:00:36.788666Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataset = MVTecDataset(\n",
    "    TaskType.SEGMENTATION,\n",
    "    args.dataset_path,\n",
    "    args.category,\n",
    "    Split.TRAIN,\n",
    "    img_size=(256, 256),\n",
    ")\n",
    "\n",
    "test_dataset = MVTecDataset(\n",
    "    TaskType.SEGMENTATION,\n",
    "    args.dataset_path,\n",
    "    args.category,\n",
    "    Split.TEST,\n",
    "    img_size=(256, 256),\n",
    ")\n",
    "\n",
    "train_dataset.load_dataset()\n",
    "test_dataset.load_dataset()\n",
    "\n",
    "# train_dataset.contaminate(test_dataset, 0.1)"
   ],
   "id": "ff98968b02ba8479",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T16:14:58.297434Z",
     "start_time": "2024-12-04T16:00:45.775575Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(3)\n",
    "results, best_results = train_cfa(train_dataset,\n",
    "                                  test_dataset,\n",
    "                                  32,\n",
    "                                  args.category, args.backbone,\n",
    "                                  args.ad_layers,\n",
    "                                  args.epochs,\n",
    "                                  args.save_path, args.device)\n"
   ],
   "id": "c4a817d61780e955",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CFA for category: pill \n",
      "\n",
      "Length train dataset: 267\n",
      "Length test dataset: 167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  7.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:09<00:00,  1.20s/it]\n",
      "Eval: 100%|██████████| 5/5 [00:02<00:00,  1.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End training performances:\n",
      "\n",
      "                img_roc: 0.8062222222222222 \n",
      "\n",
      "                pxl_roc: 0.9602539765799462 \n",
      "\n",
      "                f1_img: 0.9178082191780821 \n",
      "\n",
      "                f1_pxl: 0.6092782512754819 \n",
      "\n",
      "                img_pr: 0.9613449856074278 \n",
      "\n",
      "                pxl_pr: 0.6134243473053876 \n",
      "\n",
      "                pxl_pro: 0.927173732535669 \n",
      "\n",
      "            \n",
      "EPOCH: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:07<00:00,  1.13it/s]\n",
      "Eval: 100%|██████████| 5/5 [00:02<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End training performances:\n",
      "\n",
      "                img_roc: 0.8562962962962962 \n",
      "\n",
      "                pxl_roc: 0.9737677073361425 \n",
      "\n",
      "                f1_img: 0.9215017064846416 \n",
      "\n",
      "                f1_pxl: 0.635610162228743 \n",
      "\n",
      "                img_pr: 0.9691788367793465 \n",
      "\n",
      "                pxl_pr: 0.6783865957688482 \n",
      "\n",
      "                pxl_pro: 0.9501416732218404 \n",
      "\n",
      "            \n",
      "EPOCH: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:06<00:00,  1.17it/s]\n",
      "Eval: 100%|██████████| 5/5 [00:02<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End training performances:\n",
      "\n",
      "                img_roc: 0.8860505166475315 \n",
      "\n",
      "                pxl_roc: 0.9809472137233818 \n",
      "\n",
      "                f1_img: 0.924187725631769 \n",
      "\n",
      "                f1_pxl: 0.7095257881154479 \n",
      "\n",
      "                img_pr: 0.9762158926947507 \n",
      "\n",
      "                pxl_pr: 0.7730713294630963 \n",
      "\n",
      "                pxl_pro: 0.9599679939454481 \n",
      "\n",
      "            \n",
      "EPOCH: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:06<00:00,  1.18it/s]\n",
      "Eval: 100%|██████████| 5/5 [00:02<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End training performances:\n",
      "\n",
      "                img_roc: 0.9241481481481482 \n",
      "\n",
      "                pxl_roc: 0.984603976176516 \n",
      "\n",
      "                f1_img: 0.935361216730038 \n",
      "\n",
      "                f1_pxl: 0.7538414416961523 \n",
      "\n",
      "                img_pr: 0.9859866248128064 \n",
      "\n",
      "                pxl_pr: 0.8202532917444509 \n",
      "\n",
      "                pxl_pro: 0.968462926445346 \n",
      "\n",
      "            \n",
      "EPOCH: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:06<00:00,  1.17it/s]\n",
      "Eval: 100%|██████████| 5/5 [00:02<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End training performances:\n",
      "\n",
      "                img_roc: 0.9253333333333333 \n",
      "\n",
      "                pxl_roc: 0.9865188266709733 \n",
      "\n",
      "                f1_img: 0.9368029739776952 \n",
      "\n",
      "                f1_pxl: 0.7557227398454691 \n",
      "\n",
      "                img_pr: 0.9861042896176254 \n",
      "\n",
      "                pxl_pr: 0.8273007575888915 \n",
      "\n",
      "                pxl_pro: 0.9685549308609677 \n",
      "\n",
      "            \n",
      "EPOCH: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:07<00:00,  1.05it/s]\n",
      "Eval: 100%|██████████| 5/5 [00:02<00:00,  2.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End training performances:\n",
      "\n",
      "                img_roc: 0.9365925925925925 \n",
      "\n",
      "                pxl_roc: 0.9860383332511551 \n",
      "\n",
      "                f1_img: 0.9368029739776952 \n",
      "\n",
      "                f1_pxl: 0.763276518012883 \n",
      "\n",
      "                img_pr: 0.9884864452521794 \n",
      "\n",
      "                pxl_pr: 0.8323137548175957 \n",
      "\n",
      "                pxl_pro: 0.9705934129466159 \n",
      "\n",
      "            \n",
      "EPOCH: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:06<00:00,  1.25it/s]\n",
      "Eval: 100%|██████████| 5/5 [00:01<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End training performances:\n",
      "\n",
      "                img_roc: 0.9270952927669347 \n",
      "\n",
      "                pxl_roc: 0.9863140048369957 \n",
      "\n",
      "                f1_img: 0.9402985074626865 \n",
      "\n",
      "                f1_pxl: 0.7639703775207012 \n",
      "\n",
      "                img_pr: 0.9853477066321792 \n",
      "\n",
      "                pxl_pr: 0.8342957731914017 \n",
      "\n",
      "                pxl_pro: 0.9710253605613676 \n",
      "\n",
      "            \n",
      "EPOCH: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:06<00:00,  1.27it/s]\n",
      "Eval: 100%|██████████| 5/5 [00:01<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End training performances:\n",
      "\n",
      "                img_roc: 0.9252450980392157 \n",
      "\n",
      "                pxl_roc: 0.9875583331032042 \n",
      "\n",
      "                f1_img: 0.9450549450549451 \n",
      "\n",
      "                f1_pxl: 0.7683732567041307 \n",
      "\n",
      "                img_pr: 0.9863483115980929 \n",
      "\n",
      "                pxl_pr: 0.8394398413373247 \n",
      "\n",
      "                pxl_pro: 0.9717512486707859 \n",
      "\n",
      "            \n",
      "EPOCH: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:06<00:00,  1.16it/s]\n",
      "Eval: 100%|██████████| 5/5 [00:02<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End training performances:\n",
      "\n",
      "                img_roc: 0.936280137772675 \n",
      "\n",
      "                pxl_roc: 0.9872933875555688 \n",
      "\n",
      "                f1_img: 0.9477611940298507 \n",
      "\n",
      "                f1_pxl: 0.7667568666489072 \n",
      "\n",
      "                img_pr: 0.9870619748394399 \n",
      "\n",
      "                pxl_pr: 0.8378004297729252 \n",
      "\n",
      "                pxl_pro: 0.9737220198986365 \n",
      "\n",
      "            \n",
      "EPOCH: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:07<00:00,  1.14it/s]\n",
      "Eval: 100%|██████████| 5/5 [00:01<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End training performances:\n",
      "\n",
      "                img_roc: 0.938962962962963 \n",
      "\n",
      "                pxl_roc: 0.9859836504862707 \n",
      "\n",
      "                f1_img: 0.952029520295203 \n",
      "\n",
      "                f1_pxl: 0.7455732956914143 \n",
      "\n",
      "                img_pr: 0.9882937047349885 \n",
      "\n",
      "                pxl_pr: 0.8121590560386425 \n",
      "\n",
      "                pxl_pro: 0.9727151210740097 \n",
      "\n",
      "            \n",
      "EPOCH: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:07<00:00,  1.05it/s]\n",
      "Eval: 100%|██████████| 5/5 [00:02<00:00,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End training performances:\n",
      "\n",
      "                img_roc: 0.9374814814814815 \n",
      "\n",
      "                pxl_roc: 0.9875332951783171 \n",
      "\n",
      "                f1_img: 0.9481481481481482 \n",
      "\n",
      "                f1_pxl: 0.7648334786399302 \n",
      "\n",
      "                img_pr: 0.9880484733942574 \n",
      "\n",
      "                pxl_pr: 0.8381884941309633 \n",
      "\n",
      "                pxl_pro: 0.9727164234748599 \n",
      "\n",
      "            \n",
      "EPOCH: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:09<00:00,  1.16s/it]\n",
      "Eval: 100%|██████████| 5/5 [00:02<00:00,  2.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End training performances:\n",
      "\n",
      "                img_roc: 0.933037037037037 \n",
      "\n",
      "                pxl_roc: 0.9875168693855781 \n",
      "\n",
      "                f1_img: 0.9416058394160584 \n",
      "\n",
      "                f1_pxl: 0.7646713615023474 \n",
      "\n",
      "                img_pr: 0.9872067747807534 \n",
      "\n",
      "                pxl_pr: 0.8382745157194178 \n",
      "\n",
      "                pxl_pro: 0.9724452468873045 \n",
      "\n",
      "            \n",
      "EPOCH: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:06<00:00,  1.19it/s]\n",
      "Eval: 100%|██████████| 5/5 [00:02<00:00,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End training performances:\n",
      "\n",
      "                img_roc: 0.9359931113662457 \n",
      "\n",
      "                pxl_roc: 0.9878184807040895 \n",
      "\n",
      "                f1_img: 0.9425287356321839 \n",
      "\n",
      "                f1_pxl: 0.7654189814528828 \n",
      "\n",
      "                img_pr: 0.9873265082412794 \n",
      "\n",
      "                pxl_pr: 0.8394625664970801 \n",
      "\n",
      "                pxl_pro: 0.9721410029596577 \n",
      "\n",
      "            \n",
      "EPOCH: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:06<00:00,  1.14it/s]\n",
      "Eval: 100%|██████████| 5/5 [00:02<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End training performances:\n",
      "\n",
      "                img_roc: 0.9339259259259259 \n",
      "\n",
      "                pxl_roc: 0.9886908635060484 \n",
      "\n",
      "                f1_img: 0.9433962264150944 \n",
      "\n",
      "                f1_pxl: 0.7609533777607017 \n",
      "\n",
      "                img_pr: 0.9875102024650091 \n",
      "\n",
      "                pxl_pr: 0.8394357312369168 \n",
      "\n",
      "                pxl_pro: 0.9737400155000389 \n",
      "\n",
      "            \n",
      "EPOCH: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:07<00:00,  1.13it/s]\n",
      "Eval: 100%|██████████| 5/5 [00:02<00:00,  2.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End training performances:\n",
      "\n",
      "                img_roc: 0.9374282433983926 \n",
      "\n",
      "                pxl_roc: 0.9880813547635118 \n",
      "\n",
      "                f1_img: 0.9420849420849421 \n",
      "\n",
      "                f1_pxl: 0.7646611636045978 \n",
      "\n",
      "                img_pr: 0.9877507262273135 \n",
      "\n",
      "                pxl_pr: 0.8392509426429695 \n",
      "\n",
      "                pxl_pro: 0.9725938352530662 \n",
      "\n",
      "            \n",
      "EPOCH: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:07<00:00,  1.08it/s]\n",
      "Eval: 100%|██████████| 5/5 [00:02<00:00,  2.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End training performances:\n",
      "\n",
      "                img_roc: 0.9381127450980392 \n",
      "\n",
      "                pxl_roc: 0.9878396229311885 \n",
      "\n",
      "                f1_img: 0.9473684210526316 \n",
      "\n",
      "                f1_pxl: 0.7619792236194642 \n",
      "\n",
      "                img_pr: 0.988835367048107 \n",
      "\n",
      "                pxl_pr: 0.8370194432407598 \n",
      "\n",
      "                pxl_pro: 0.972630890067927 \n",
      "\n",
      "            \n",
      "EPOCH: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:06<00:00,  1.21it/s]\n",
      "Eval: 100%|██████████| 5/5 [00:01<00:00,  2.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End training performances:\n",
      "\n",
      "                img_roc: 0.939950980392157 \n",
      "\n",
      "                pxl_roc: 0.987998910330564 \n",
      "\n",
      "                f1_img: 0.9477611940298508 \n",
      "\n",
      "                f1_pxl: 0.7616526912446714 \n",
      "\n",
      "                img_pr: 0.9891627555480653 \n",
      "\n",
      "                pxl_pr: 0.8371349971551888 \n",
      "\n",
      "                pxl_pro: 0.9722064282322649 \n",
      "\n",
      "            \n",
      "EPOCH: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:06<00:00,  1.20it/s]\n",
      "Eval: 100%|██████████| 5/5 [00:02<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End training performances:\n",
      "\n",
      "                img_roc: 0.9451593137254902 \n",
      "\n",
      "                pxl_roc: 0.9886017660361474 \n",
      "\n",
      "                f1_img: 0.9473684210526316 \n",
      "\n",
      "                f1_pxl: 0.7673066721780166 \n",
      "\n",
      "                img_pr: 0.9903223338692928 \n",
      "\n",
      "                pxl_pr: 0.8423655588627437 \n",
      "\n",
      "                pxl_pro: 0.9734524272385271 \n",
      "\n",
      "            \n",
      "EPOCH: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:06<00:00,  1.20it/s]\n",
      "Eval: 100%|██████████| 5/5 [00:02<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End training performances:\n",
      "\n",
      "                img_roc: 0.9357037037037036 \n",
      "\n",
      "                pxl_roc: 0.988715004951743 \n",
      "\n",
      "                f1_img: 0.9433962264150944 \n",
      "\n",
      "                f1_pxl: 0.7671679671975683 \n",
      "\n",
      "                img_pr: 0.9879431650827156 \n",
      "\n",
      "                pxl_pr: 0.8428377125438736 \n",
      "\n",
      "                pxl_pro: 0.9726327936951854 \n",
      "\n",
      "            \n",
      "EPOCH: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:08<00:00,  1.09s/it]\n",
      "Eval: 100%|██████████| 5/5 [00:02<00:00,  2.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End training performances:\n",
      "\n",
      "                img_roc: 0.9377777777777778 \n",
      "\n",
      "                pxl_roc: 0.9873347914647002 \n",
      "\n",
      "                f1_img: 0.9469696969696969 \n",
      "\n",
      "                f1_pxl: 0.7348308607604592 \n",
      "\n",
      "                img_pr: 0.988336771159319 \n",
      "\n",
      "                pxl_pr: 0.8063909148946173 \n",
      "\n",
      "                pxl_pro: 0.9728049457353258 \n",
      "\n",
      "            \n",
      "EPOCH: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:06<00:00,  1.18it/s]\n",
      "Eval: 100%|██████████| 5/5 [00:02<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End training performances:\n",
      "\n",
      "                img_roc: 0.9371412169919634 \n",
      "\n",
      "                pxl_roc: 0.9887522846683245 \n",
      "\n",
      "                f1_img: 0.946969696969697 \n",
      "\n",
      "                f1_pxl: 0.7664564386359559 \n",
      "\n",
      "                img_pr: 0.9877084534296561 \n",
      "\n",
      "                pxl_pr: 0.8443166708196819 \n",
      "\n",
      "                pxl_pro: 0.9718264666106617 \n",
      "\n",
      "            \n",
      "EPOCH: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:06<00:00,  1.17it/s]\n",
      "Eval: 100%|██████████| 5/5 [00:02<00:00,  2.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End training performances:\n",
      "\n",
      "                img_roc: 0.9371412169919633 \n",
      "\n",
      "                pxl_roc: 0.9885152624236527 \n",
      "\n",
      "                f1_img: 0.946969696969697 \n",
      "\n",
      "                f1_pxl: 0.7562617629999645 \n",
      "\n",
      "                img_pr: 0.9877513440798483 \n",
      "\n",
      "                pxl_pr: 0.8328642658633651 \n",
      "\n",
      "                pxl_pro: 0.9728124627648296 \n",
      "\n",
      "            \n",
      "EPOCH: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:07<00:00,  1.10it/s]\n",
      "Eval: 100%|██████████| 5/5 [00:02<00:00,  2.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End training performances:\n",
      "\n",
      "                img_roc: 0.9377777777777778 \n",
      "\n",
      "                pxl_roc: 0.9885017592341947 \n",
      "\n",
      "                f1_img: 0.9473684210526315 \n",
      "\n",
      "                f1_pxl: 0.7598220202593962 \n",
      "\n",
      "                img_pr: 0.9883018037840812 \n",
      "\n",
      "                pxl_pr: 0.8368847716273713 \n",
      "\n",
      "                pxl_pro: 0.9735412330715645 \n",
      "\n",
      "            \n",
      "EPOCH: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:06<00:00,  1.19it/s]\n",
      "Eval: 100%|██████████| 5/5 [00:02<00:00,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End training performances:\n",
      "\n",
      "                img_roc: 0.949037037037037 \n",
      "\n",
      "                pxl_roc: 0.9886557882703237 \n",
      "\n",
      "                f1_img: 0.9509433962264151 \n",
      "\n",
      "                f1_pxl: 0.7613605509682879 \n",
      "\n",
      "                img_pr: 0.9908770500803922 \n",
      "\n",
      "                pxl_pr: 0.8377919721197656 \n",
      "\n",
      "                pxl_pro: 0.971964883934373 \n",
      "\n",
      "            \n",
      "EPOCH: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:08<00:00,  1.09s/it]\n",
      "Eval: 100%|██████████| 5/5 [00:02<00:00,  2.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End training performances:\n",
      "\n",
      "                img_roc: 0.94345579793341 \n",
      "\n",
      "                pxl_roc: 0.9889785981069538 \n",
      "\n",
      "                f1_img: 0.9509433962264152 \n",
      "\n",
      "                f1_pxl: 0.7560422528389452 \n",
      "\n",
      "                img_pr: 0.9889152137274564 \n",
      "\n",
      "                pxl_pr: 0.8342547945005327 \n",
      "\n",
      "                pxl_pro: 0.9746829023950239 \n",
      "\n",
      "            \n",
      "EPOCH: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:06<00:00,  1.16it/s]\n",
      "Eval: 100%|██████████| 5/5 [00:02<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End training performances:\n",
      "\n",
      "                img_roc: 0.9410370370370371 \n",
      "\n",
      "                pxl_roc: 0.9871583357291689 \n",
      "\n",
      "                f1_img: 0.9509433962264151 \n",
      "\n",
      "                f1_pxl: 0.7254488839648563 \n",
      "\n",
      "                img_pr: 0.9889666452204393 \n",
      "\n",
      "                pxl_pr: 0.7867217568779036 \n",
      "\n",
      "                pxl_pro: 0.9738488753032778 \n",
      "\n",
      "            \n",
      "EPOCH: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:06<00:00,  1.25it/s]\n",
      "Eval: 100%|██████████| 5/5 [00:01<00:00,  2.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End training performances:\n",
      "\n",
      "                img_roc: 0.9392592592592592 \n",
      "\n",
      "                pxl_roc: 0.9887346651673262 \n",
      "\n",
      "                f1_img: 0.9473684210526315 \n",
      "\n",
      "                f1_pxl: 0.7592868424531245 \n",
      "\n",
      "                img_pr: 0.9888061311987377 \n",
      "\n",
      "                pxl_pr: 0.8358749608494362 \n",
      "\n",
      "                pxl_pro: 0.9718796063842916 \n",
      "\n",
      "            \n",
      "EPOCH: 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:07<00:00,  1.06it/s]\n",
      "Eval: 100%|██████████| 5/5 [00:02<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End training performances:\n",
      "\n",
      "                img_roc: 0.938074074074074 \n",
      "\n",
      "                pxl_roc: 0.9891376184071101 \n",
      "\n",
      "                f1_img: 0.9473684210526315 \n",
      "\n",
      "                f1_pxl: 0.7642789443754081 \n",
      "\n",
      "                img_pr: 0.9883670282429518 \n",
      "\n",
      "                pxl_pr: 0.8418363153822283 \n",
      "\n",
      "                pxl_pro: 0.9722716942308036 \n",
      "\n",
      "            \n",
      "EPOCH: 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:06<00:00,  1.20it/s]\n",
      "Eval: 100%|██████████| 5/5 [00:02<00:00,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End training performances:\n",
      "\n",
      "                img_roc: 0.936 \n",
      "\n",
      "                pxl_roc: 0.9887841357474054 \n",
      "\n",
      "                f1_img: 0.9473684210526315 \n",
      "\n",
      "                f1_pxl: 0.7587311427980988 \n",
      "\n",
      "                img_pr: 0.9880547516059036 \n",
      "\n",
      "                pxl_pr: 0.8356003026561671 \n",
      "\n",
      "                pxl_pro: 0.9732505145391501 \n",
      "\n",
      "            \n",
      "EPOCH: 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:07<00:00,  1.05it/s]\n",
      "Eval: 100%|██████████| 5/5 [00:02<00:00,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End training performances:\n",
      "\n",
      "                img_roc: 0.9377777777777778 \n",
      "\n",
      "                pxl_roc: 0.9885525282931087 \n",
      "\n",
      "                f1_img: 0.9473684210526315 \n",
      "\n",
      "                f1_pxl: 0.7565508045504936 \n",
      "\n",
      "                img_pr: 0.9882392494352358 \n",
      "\n",
      "                pxl_pr: 0.834102695745027 \n",
      "\n",
      "                pxl_pro: 0.9729937768266892 \n",
      "\n",
      "            \n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import wandb\n",
    "run = wandb.init(project=\"my-model-training-project\")\n",
    "run.config = {\"epochs\": 1337, \"learning_rate\": 3e-4}\n",
    "run.log({\"metric\": 42})\n",
    "my_model_artifact = run.log_artifact(\"./my_model.pt\", type=\"model\")"
   ],
   "id": "62640aa2d4f83a3b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T16:19:33.311077Z",
     "start_time": "2024-12-04T16:18:03.066309Z"
    }
   },
   "cell_type": "code",
   "source": [
    "epochs = range(1, args.epochs)\n",
    "\n",
    "plt.plot(epochs, results.img_roc, label='img_roc')\n",
    "plt.plot(epochs, results.pxl_roc, label='pxl_roc')\n",
    "plt.plot(epochs, results.f1_img, label='f1_img')\n",
    "plt.plot(epochs, results.f1_pxl, label='f1_pxl')\n",
    "plt.plot(epochs, results.img_pr, label='img_pr')\n",
    "plt.plot(epochs, results.pxl_pr, label='pxl_pr')\n",
    "plt.plot(epochs, results.pxl_pro, label='pxl_pro')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ],
   "id": "84781af026d10592",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[12], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m epochs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m, args\u001B[38;5;241m.\u001B[39mepochs)\n\u001B[1;32m----> 3\u001B[0m \u001B[43mplt\u001B[49m\u001B[38;5;241m.\u001B[39mplot(epochs, results\u001B[38;5;241m.\u001B[39mimg_roc, label\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mimg_roc\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      4\u001B[0m plt\u001B[38;5;241m.\u001B[39mplot(epochs, results\u001B[38;5;241m.\u001B[39mpxl_roc, label\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpxl_roc\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      5\u001B[0m plt\u001B[38;5;241m.\u001B[39mplot(epochs, results\u001B[38;5;241m.\u001B[39mf1_img, label\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mf1_img\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32m_pydevd_bundle\\\\pydevd_cython_win32_312_64.pyx:1187\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_312_64.SafeCallWrapper.__call__\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\\\pydevd_cython_win32_312_64.pyx:627\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_312_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\\\pydevd_cython_win32_312_64.pyx:937\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_312_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\\\pydevd_cython_win32_312_64.pyx:928\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_312_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\\\pydevd_cython_win32_312_64.pyx:585\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_312_64.PyDBFrame.do_wait_suspend\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\PyCharm Professional\\plugins\\python-ce\\helpers\\pydev\\pydevd.py:1220\u001B[0m, in \u001B[0;36mPyDB.do_wait_suspend\u001B[1;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[0;32m   1217\u001B[0m         from_this_thread\u001B[38;5;241m.\u001B[39mappend(frame_id)\n\u001B[0;32m   1219\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_threads_suspended_single_notification\u001B[38;5;241m.\u001B[39mnotify_thread_suspended(thread_id, stop_reason):\n\u001B[1;32m-> 1220\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_do_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msuspend_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrom_this_thread\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\PyCharm Professional\\plugins\\python-ce\\helpers\\pydev\\pydevd.py:1235\u001B[0m, in \u001B[0;36mPyDB._do_wait_suspend\u001B[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[0;32m   1232\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_mpl_hook()\n\u001B[0;32m   1234\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess_internal_commands()\n\u001B[1;32m-> 1235\u001B[0m         \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1237\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcancel_async_evaluation(get_current_thread_id(thread), \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mid\u001B[39m(frame)))\n\u001B[0;32m   1239\u001B[0m \u001B[38;5;66;03m# process any stepping instructions\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T16:43:08.981737300Z",
     "start_time": "2024-12-03T16:34:31.107502Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataset = MVTecDataset(\n",
    "    TaskType.SEGMENTATION,\n",
    "    args.dataset_path,\n",
    "    args.category,\n",
    "    Split.TRAIN,\n",
    "    img_size=(256, 256),\n",
    ")\n",
    "\n",
    "test_dataset = MVTecDataset(\n",
    "    TaskType.SEGMENTATION,\n",
    "    args.dataset_path,\n",
    "    args.category,\n",
    "    Split.TEST,\n",
    "    img_size=(256, 256),\n",
    ")\n",
    "\n",
    "train_dataset.load_dataset()\n",
    "test_dataset.load_dataset()"
   ],
   "id": "f19a0947f11cfd91",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T16:42:51.772749Z",
     "start_time": "2024-12-03T16:42:50.740786Z"
    }
   },
   "cell_type": "code",
   "source": [
    "args.save_path = \"./patch_unsupervised.pt\"\n",
    "args.model_checkpoint_path = \"./patch_unsupervised.pt\"\n",
    "results_unsupervised, best_results_unsupervised = train_cfa(train_dataset, test_dataset, 8, args.category, args.backbone,\n",
    "                                                            args.ad_layers,\n",
    "                                                            args.epochs,\n",
    "                                                            args.save_path, args.device)"
   ],
   "id": "686664bd2596562e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CFA for category: pill \n",
      "\n",
      "Length train dataset: 267\n",
      "Length test dataset: 167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:00<00:00, 93.16it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/33 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[23], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m args\u001B[38;5;241m.\u001B[39msave_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m./patch_unsupervised.pt\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m      2\u001B[0m args\u001B[38;5;241m.\u001B[39mmodel_checkpoint_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m./patch_unsupervised.pt\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m----> 3\u001B[0m results_unsupervised, best_results_unsupervised \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_cfa\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_dataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_dataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m8\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcategory\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackbone\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m                                                            \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mad_layers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m                                                            \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[43m                                                            \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msave_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\moviad\\moviad\\entrypoints\\cfa.py:36\u001B[0m, in \u001B[0;36mtrain_cfa\u001B[1;34m(train_dataset, test_dataset, batch_size, category, backbone, ad_layers, epochs, save_path, device)\u001B[0m\n\u001B[0;32m     33\u001B[0m cfa_model \u001B[38;5;241m=\u001B[39m cfa_model\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m     35\u001B[0m trainer \u001B[38;5;241m=\u001B[39m TrainerCFA(cfa_model, backbone, feature_extractor, train_dataloader, test_dataloader, category, device)\n\u001B[1;32m---> 36\u001B[0m results, best_results \u001B[38;5;241m=\u001B[39m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     38\u001B[0m \u001B[38;5;66;03m# save the model\u001B[39;00m\n\u001B[0;32m     39\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m save_path:\n",
      "File \u001B[1;32mE:\\moviad\\moviad\\trainers\\trainer_cfa.py:99\u001B[0m, in \u001B[0;36mTrainerCFA.train\u001B[1;34m(self, epochs)\u001B[0m\n\u001B[0;32m     90\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     91\u001B[0m \u001B[38;5;124;03m    p = self.feature_extractor(batch.to(self.device))\u001B[39;00m\n\u001B[0;32m     92\u001B[0m \u001B[38;5;124;03m    if isinstance(p, dict):\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     95\u001B[0m \u001B[38;5;124;03m    loss, _ = self.cfa_model(p)\u001B[39;00m\n\u001B[0;32m     96\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m     97\u001B[0m     loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcfa_model(batch\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice))\n\u001B[1;32m---> 99\u001B[0m     \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    100\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[0;32m    102\u001B[0m img_roc, pxl_roc, f1_img, f1_pxl, img_pr, pxl_pr, pxl_pro \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mevaluator\u001B[38;5;241m.\u001B[39mevaluate(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcfa_model)\n",
      "File \u001B[1;32mE:\\.venvs\\env\\Lib\\site-packages\\torch\\_tensor.py:581\u001B[0m, in \u001B[0;36mTensor.backward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    571\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    572\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m    573\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[0;32m    574\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    579\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[0;32m    580\u001B[0m     )\n\u001B[1;32m--> 581\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    582\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[0;32m    583\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\.venvs\\env\\Lib\\site-packages\\torch\\autograd\\__init__.py:347\u001B[0m, in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    342\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[0;32m    344\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[0;32m    345\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[0;32m    346\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[1;32m--> 347\u001B[0m \u001B[43m_engine_run_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    348\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    349\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    350\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    351\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    352\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    353\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    354\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    355\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\.venvs\\env\\Lib\\site-packages\\torch\\autograd\\graph.py:825\u001B[0m, in \u001B[0;36m_engine_run_backward\u001B[1;34m(t_outputs, *args, **kwargs)\u001B[0m\n\u001B[0;32m    823\u001B[0m     unregister_hooks \u001B[38;5;241m=\u001B[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[0;32m    824\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 825\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[0;32m    826\u001B[0m \u001B[43m        \u001B[49m\u001B[43mt_outputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[0;32m    827\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[0;32m    828\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    829\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[1;31mRuntimeError\u001B[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "image_entry = train_dataset.__getitem__(2)\n",
    "\n",
    "\n"
   ],
   "id": "63688c16a38156cc",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
